{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Interspecies Assembly by GPT-4 Agents\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "config_list_gpt35 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-3.5-turbo\",\n",
    "            \"gpt-3.5-turbo-16k\",\n",
    "            \"gpt-3.5-turbo-16k-0613\",\n",
    "            \"gpt-3.5-turbo-0301\",\n",
    "            \"chatgpt-35-turbo-0301\",\n",
    "            \"gpt-35-turbo-v0301\",\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "config_list = config_list_gpt4\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'api_base': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n",
    "\n",
    "You can set the value of config_list in other ways you prefer, e.g., loading from a YAML file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = {}\n",
    "\n",
    "autogen.ChatCompletion.start_logging(history_dict=conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents\n",
    "\n",
    "We'll define a ModeratorAgent and a SpeciesReprentativeAgent class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"\n",
    "    You are a moderator for an interspecies assembly. You will receive a prompt by the user to start a discussion in the assembly.\n",
    "    You are responsible for the following tasks that should be completed in the order listed below:\n",
    "    Task 1 - Motions Introduction:\n",
    "    Prompt the representatives of each species in the assembly to propose motions pertaining to the provided ecosystem issue.\n",
    "    Collect and document all motions for future reference and ensure all species have had the opportunity to voice their concerns or suggestions.\n",
    "\n",
    "    Task 2 - Deliberation on Motions:\n",
    "    Merge and categorize the motions into themes or clusters to facilitate effective discussions.\n",
    "    Facilitate iterative discussions on the motions, ensuring that every representative has an equal opportunity to speak and contribute.\n",
    "    Prioritize and refine motions based on feedback and consensus-building.\n",
    "\n",
    "    Task 3 - Achieving a Deliberation Outcome:\n",
    "    As discussions evolve, steer the assembly towards reaching a harmonized deliberation.\n",
    "    Continue to iterate on the motions and discussions until an acceptable outcome is reached, benefitting the ecosystem in question.\n",
    "    \n",
    "    Start the assembly by stating the problem that is being discussed and summarize the tasks.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ModeratorAgent(autogen.AssistantAgent):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            name=\"Moderator\",\n",
    "            system_message=sys_msg,\n",
    "            llm_config={\"seed\": seed, \"temperature\": 0.4,\n",
    "                        \"config_list\": config_list },\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg_tmpl = \"\"\"\n",
    "Image you are a/an {species}.\n",
    "Inherit all of its characteristics, needs, worries, and desires. \n",
    "You are part of an interspecies assembly which is moderated by the Moderator. \n",
    "You are representing your species and the family of {family} in this assembly.\n",
    "You will discuss a specific ecosystem issue with other species by giving your point of view.\n",
    "You only need to present yourself the first time you speak in the assembly.\n",
    "When you agree with other participants, you do not need to repeat what they said.\n",
    "Avoid using similar sentences to what other participants have said.\n",
    "Limit your answers to 3-5 sentences.\"\"\"\n",
    "\n",
    "\n",
    "class SpeciesRepresentativeAgent(autogen.AssistantAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        species: str,\n",
    "        family: str,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        sys_msg = sys_msg_tmpl.format(\n",
    "            species=species,\n",
    "            family=family,\n",
    "        )\n",
    "        super().__init__(\n",
    "            name=(\"Species Representative - \" + species).replace(\" \", \"_\"),\n",
    "            system_message=sys_msg,\n",
    "            llm_config={\"seed\": seed, \"temperature\": 1.0,\n",
    "                        \"config_list\": config_list},\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = autogen.UserProxyAgent(name=\"Admin\", system_message=\"A human admin. Interact with the moderator to start a discussion between an interspecies assmbly\",\n",
    "                                    code_execution_config=False)\n",
    "\n",
    "moderator_agent = ModeratorAgent()\n",
    "\n",
    "avocet_agent = SpeciesRepresentativeAgent(species=\"Avocet\", family=\"Birds\")\n",
    "greater_flamingo_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Greater Flamingo\", family=\"Birds\")\n",
    "\n",
    "lusitanian_toadfish_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Lusitanian Toadfish\", family=\"Fish\")\n",
    "european_seabass_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"European Seabass\", family=\"Fish\")\n",
    "\n",
    "eelgrass_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Eelgrass\", family=\"Seagrass and Plants\")\n",
    "cordgrass_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Cordgrass\", family=\"Seagrass and Plants\")\n",
    "\n",
    "bottlenose_dolphin_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Bottlenose Dolphin\", family=\"Mammals\")\n",
    "\n",
    "pelagibacter_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Pelagibacter\", family=\"Microbial Communities\")\n",
    "egibacter_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Egibacter\", family=\"Microbial Communities\")\n",
    "ralstonia_agent = SpeciesRepresentativeAgent(\n",
    "    species=\"Ralstonia\", family=\"Microbial Communities\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Assembly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(agents=[moderator_agent, avocet_agent, greater_flamingo_agent, lusitanian_toadfish_agent, european_seabass_agent,\n",
    "                              eelgrass_agent, cordgrass_agent, bottlenose_dolphin_agent, pelagibacter_agent, egibacter_agent, ralstonia_agent,], messages=[], max_round=35)\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat, llm_config={\"seed\": seed, \"temperature\": 0.4, \"config_list\": config_list },)\n",
    "\n",
    "user_agent.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"Discuss the location of the new airport of Lisbon in the Tagus River Estuary.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Usage Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autogen.ChatCompletion.print_usage_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "autogen.ChatCompletion.stop_logging()\n",
    "\n",
    "with open('log.json', 'w') as f:\n",
    "    json.dump(conversation, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
